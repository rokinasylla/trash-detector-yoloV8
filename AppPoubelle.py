import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration
from ultralytics import YOLO
from PIL import Image
import cv2
import numpy as np
import tempfile
import os
from pathlib import Path
import time
import gdown
from io import BytesIO
import threading

# Configuration de la page
st.set_page_config(
    page_title="D√©tecteur de Poubelles YOLOv8",
    page_icon="üóëÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
        color: #FF4B4B;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        text-align: center;
        color: #666;
        margin-bottom: 2rem;
    }
    .stat-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 10px 0;
    }
    .success-box {
        background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
        padding: 15px;
        border-radius: 10px;
        color: white;
        margin: 10px 0;
    }
    .live-badge {
        background: #ff0000;
        color: white;
        padding: 5px 15px;
        border-radius: 20px;
        font-weight: bold;
        animation: pulse 2s infinite;
    }
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
</style>
""", unsafe_allow_html=True)

# ========== CONFIGURATION DU MOD√àLE ==========
MODEL_GDRIVE_URL = "https://drive.google.com/uc?export=download&id=1jfH0da0ALkH7qPW0ZyYY5MIC_NfIIBrq"
MODEL_PATH = "best.pt"

# Configuration WebRTC
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

# ========== FONCTION DE T√âL√âCHARGEMENT DU MOD√àLE ==========
@st.cache_resource
def download_and_load_model():
    """T√©l√©charge le mod√®le depuis Google Drive et le charge"""
    try:
        if not os.path.exists(MODEL_PATH):
            st.info("üì• T√©l√©chargement du mod√®le... (premi√®re utilisation)")
            gdown.download(MODEL_GDRIVE_URL, MODEL_PATH, quiet=False)
            
            if not os.path.exists(MODEL_PATH):
                st.error("‚ùå √âchec du t√©l√©chargement du mod√®le")
                return None
        
        model = YOLO(MODEL_PATH)
        return model
    
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement du mod√®le: {str(e)}")
        return None

# ========== CLASSE VIDEO PROCESSOR POUR WEBRTC ==========
class YOLOVideoProcessor(VideoProcessorBase):
    """Processeur vid√©o pour la d√©tection YOLOv8 en temps r√©el"""
    
    def __init__(self):
        self.model = None
        self.confidence = 0.5
        self.iou_threshold = 0.45
        self.frame_count = 0
        self.detection_count = 0
        self.fps_list = []
        self.last_time = time.time()
        self.lock = threading.Lock()
    
    def set_model(self, model):
        """D√©finir le mod√®le YOLO"""
        with self.lock:
            self.model = model
    
    def set_confidence(self, confidence):
        """D√©finir le seuil de confiance"""
        with self.lock:
            self.confidence = confidence
    
    def set_iou(self, iou):
        """D√©finir le seuil IoU"""
        with self.lock:
            self.iou_threshold = iou
    
    def recv(self, frame):
        """Traiter chaque frame de la webcam"""
        img = frame.to_ndarray(format="bgr24")
        
        with self.lock:
            if self.model is None:
                return frame
            
            try:
                # Calculer le FPS
                current_time = time.time()
                fps = 1 / (current_time - self.last_time) if (current_time - self.last_time) > 0 else 0
                self.last_time = current_time
                self.fps_list.append(fps)
                if len(self.fps_list) > 30:
                    self.fps_list.pop(0)
                avg_fps = np.mean(self.fps_list)
                
                # D√©tection YOLOv8
                results = self.model.predict(
                    img,
                    conf=self.confidence,
                    iou=self.iou_threshold,
                    verbose=False
                )
                
                # Annoter l'image
                annotated_img = results[0].plot()
                
                # Compter les d√©tections
                num_detections = len(results[0].boxes)
                self.frame_count += 1
                self.detection_count += num_detections
                
                # Ajouter des informations sur l'image
                cv2.putText(annotated_img, f"FPS: {avg_fps:.1f}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                
                cv2.putText(annotated_img, f"Detections: {num_detections}", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
                
                # Badge LIVE
                cv2.rectangle(annotated_img, (10, 80), (100, 110), (0, 0, 255), -1)
                cv2.putText(annotated_img, "LIVE", 
                           (25, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                return frame.from_ndarray(annotated_img, format="bgr24")
                
            except Exception as e:
                # En cas d'erreur, afficher l'image originale
                cv2.putText(img, f"Error: {str(e)}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)
                return frame.from_ndarray(img, format="bgr24")

# ========== CHARGEMENT AUTOMATIQUE DU MOD√àLE ==========
if 'model' not in st.session_state or st.session_state.model is None:
    with st.spinner("üîÑ Chargement du mod√®le YOLOv8..."):
        st.session_state.model = download_and_load_model()
        if st.session_state.model is not None:
            st.session_state.model_loaded = True
        else:
            st.session_state.model_loaded = False

# Titre principal
st.markdown('<p class="main-header">üóëÔ∏è D√©tecteur de Poubelles YOLOv8</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">D√©tection en temps r√©el avec cam√©ra</p>', unsafe_allow_html=True)

# Message de statut du mod√®le
if st.session_state.model_loaded:
    st.success("‚úÖ Mod√®le charg√© et pr√™t √† l'emploi!")
else:
    st.error("‚ùå Impossible de charger le mod√®le. Veuillez v√©rifier la configuration.")
    st.stop()

# Sidebar - Configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Informations du mod√®le
    st.markdown("### üìä Informations du Mod√®le")
    if hasattr(st.session_state.model, 'names'):
        st.write(f"**Classes:** {len(st.session_state.model.names)}")
        classes_list = list(st.session_state.model.names.values())
        for idx, class_name in enumerate(classes_list):
            st.write(f"  {idx}: {class_name}")
    
    st.markdown("---")
    
    # SECTION T√âL√âCHARGEMENT DU MOD√àLE
    st.markdown("### üì• T√©l√©charger le Mod√®le")
    if os.path.exists(MODEL_PATH):
        with open(MODEL_PATH, "rb") as file:
            st.download_button(
                label="‚¨áÔ∏è T√©l√©charger best.pt",
                data=file,
                file_name="best.pt",
                mime="application/octet-stream",
                use_container_width=True
            )
    
    st.markdown("---")
    
    # Param√®tres de d√©tection
    st.markdown("### üéõÔ∏è Param√®tres de D√©tection")
    confidence = st.slider(
        "Seuil de confiance",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
        help="Confidence minimale pour les d√©tections"
    )
    
    iou_threshold = st.slider(
        "Seuil IoU (NMS)",
        min_value=0.0,
        max_value=1.0,
        value=0.45,
        step=0.05,
        help="Seuil pour la suppression des non-maxima"
    )
    
    # Options d'affichage
    st.markdown("### üé® Affichage")
    show_labels = st.checkbox("Afficher les labels", value=True)
    show_conf = st.checkbox("Afficher la confiance", value=True)
    box_thickness = st.slider("√âpaisseur des bo√Ætes", 1, 5, 2)

# Tabs principales
tab1, tab2, tab3, tab4 = st.tabs(["üìπ Cam√©ra Temps R√©el", "üì∏ Images", "üé• Vid√©os", "‚ÑπÔ∏è √Ä Propos"])

# ========== TAB 1: WEBCAM TEMPS R√âEL ==========
with tab1:
    st.header("üìπ D√©tection en Temps R√©el")
    
    st.markdown("""
    <div class="success-box">
        <h3>üé• Webcam en Direct</h3>
        <p>Activez votre webcam pour une d√©tection en temps r√©el!</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### üì∑ Flux Vid√©o")
        
        # Cr√©er le contexte WebRTC
        webrtc_ctx = webrtc_streamer(
            key="yolo-detection",
            video_processor_factory=YOLOVideoProcessor,
            rtc_configuration=RTC_CONFIGURATION,
            media_stream_constraints={
                "video": {
                    "width": {"ideal": 1280},
                    "height": {"ideal": 720}
                },
                "audio": False
            },
            async_processing=True,
        )
        
        # Configurer le mod√®le dans le processor
        if webrtc_ctx.video_processor:
            webrtc_ctx.video_processor.set_model(st.session_state.model)
            webrtc_ctx.video_processor.set_confidence(confidence)
            webrtc_ctx.video_processor.set_iou(iou_threshold)
    
    with col2:
        st.markdown("### üìä Statistiques")
        
        if webrtc_ctx.video_processor:
            stats_placeholder = st.empty()
            
            # Afficher les statistiques en temps r√©el
            if webrtc_ctx.state.playing:
                st.markdown('<p class="live-badge">üî¥ EN DIRECT</p>', unsafe_allow_html=True)
                
                with stats_placeholder.container():
                    processor = webrtc_ctx.video_processor
                    
                    st.metric("Frames trait√©s", processor.frame_count)
                    st.metric("D√©tections totales", processor.detection_count)
                    
                    if processor.frame_count > 0:
                        avg_detections = processor.detection_count / processor.frame_count
                        st.metric("Moyenne/frame", f"{avg_detections:.2f}")
                    
                    if len(processor.fps_list) > 0:
                        st.metric("FPS moyen", f"{np.mean(processor.fps_list):.1f}")
            else:
                st.info("‚ñ∂Ô∏è Cliquez sur START pour commencer")
        
        st.markdown("---")
        
        st.markdown("### ‚öôÔ∏è Contr√¥les")
        st.info("""
        **Instructions:**
        1. Cliquez sur **START**
        2. Autorisez l'acc√®s √† la cam√©ra
        3. Positionnez la poubelle devant la cam√©ra
        4. Les d√©tections s'affichent en temps r√©el!
        
        **Arr√™ter:** Cliquez sur **STOP**
        """)
    
    st.markdown("---")
    
    # Informations suppl√©mentaires
    with st.expander("üí° Conseils pour une meilleure d√©tection"):
        st.markdown("""
        ### üìå Pour de meilleurs r√©sultats:
        
        1. **√âclairage** üí°
           - Assurez un bon √©clairage
           - √âvitez les contre-jours
        
        2. **Distance** üìè
           - Gardez la poubelle √† 1-3 m√®tres
           - Cadrez enti√®rement l'objet
        
        3. **Stabilit√©** üéØ
           - Gardez la cam√©ra stable
           - √âvitez les mouvements brusques
        
        4. **Angle** üìê
           - Vue frontale ou l√©g√®rement en hauteur
           - √âvitez les angles trop obliques
        
        5. **Param√®tres** ‚öôÔ∏è
           - Ajustez la confiance si trop/pas assez de d√©tections
           - R√©duisez l'IoU si d√©tections dupliqu√©es
        """)

# ========== TAB 2: DETECTION SUR IMAGES ==========
with tab2:
    st.header("üì∏ D√©tection sur Images")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Image d'entr√©e")
        uploaded_image = st.file_uploader(
            "Choisissez une image de poubelle",
            type=['jpg', 'jpeg', 'png'],
            key="image_uploader"
        )
        
        if uploaded_image is not None:
            image = Image.open(uploaded_image)
            st.image(image, caption="Image originale", use_container_width=True)
    
    with col2:
        st.subheader("R√©sultat de d√©tection")
        
        if uploaded_image is not None:
            try:
                with st.spinner("üîç Analyse en cours..."):
                    img_array = np.array(image)
                    
                    results = st.session_state.model.predict(
                        img_array,
                        conf=confidence,
                        iou=iou_threshold,
                        verbose=False
                    )
                    
                    annotated = results[0].plot(
                        line_width=box_thickness,
                        labels=show_labels,
                        conf=show_conf
                    )
                    annotated_rgb = cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB)
                    
                    st.image(annotated_rgb, caption="D√©tections", use_container_width=True)
                    
                    boxes = results[0].boxes
                    num_detections = len(boxes)
                    
                    st.markdown(f"""
                    <div class="stat-box">
                        <h2>{num_detections}</h2>
                        <p>Objets d√©tect√©s</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    if num_detections > 0:
                        with st.expander("üìä D√©tails des d√©tections"):
                            for i, box in enumerate(boxes):
                                cls = int(box.cls[0])
                                conf_val = float(box.conf[0])
                                label = st.session_state.model.names[cls]
                                x1, y1, x2, y2 = box.xyxy[0].tolist()
                                
                                st.write(f"**Objet {i+1}:**")
                                st.write(f"  - Classe: {label}")
                                st.write(f"  - Confiance: {conf_val:.2%}")
                                st.write(f"  - Position: ({int(x1)}, {int(y1)}) ‚Üí ({int(x2)}, {int(y2)})")
                                st.markdown("---")
                        
                        result_img = Image.fromarray(annotated_rgb)
                        buf = BytesIO()
                        result_img.save(buf, format='JPEG')
                        buf.seek(0)
                        
                        st.download_button(
                            label="üì• T√©l√©charger l'image avec d√©tections",
                            data=buf,
                            file_name="detection_result.jpg",
                            mime="image/jpeg",
                            use_container_width=True
                        )
                
            except Exception as e:
                st.error(f"‚ùå Erreur lors de la d√©tection: {str(e)}")
        else:
            st.info("üëÜ Uploadez une image pour commencer la d√©tection")

# ========== TAB 3: DETECTION SUR VIDEOS ==========
with tab3:
    st.header("üé• D√©tection sur Vid√©os")
    
    uploaded_video = st.file_uploader(
        "Choisissez une vid√©o",
        type=['mp4', 'avi', 'mov', 'mkv'],
        key="video_uploader"
    )
    
    if uploaded_video is not None:
        tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
        tfile.write(uploaded_video.read())
        tfile.close()
        video_path = tfile.name
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Vid√©o originale")
            st.video(uploaded_video)
        
        with col2:
            st.subheader("Traitement")
            
            if st.button("‚ñ∂Ô∏è Lancer la d√©tection", use_container_width=True, type="primary"):
                try:
                    cap = cv2.VideoCapture(video_path)
                    
                    fps = int(cap.get(cv2.CAP_PROP_FPS))
                    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                    
                    st.info(f"üìπ Vid√©o: {width}x{height} @ {fps} FPS - {total_frames} frames")
                    
                    output_path = tempfile.mktemp(suffix='.mp4')
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
                    
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    frame_placeholder = st.empty()
                    
                    frame_count = 0
                    detection_stats = []
                    start_time = time.time()
                    
                    while cap.isOpened():
                        ret, frame = cap.read()
                        if not ret:
                            break
                        
                        results = st.session_state.model.predict(
                            frame,
                            conf=confidence,
                            iou=iou_threshold,
                            verbose=False
                        )
                        
                        annotated_frame = results[0].plot(
                            line_width=box_thickness,
                            labels=show_labels,
                            conf=show_conf
                        )
                        
                        out.write(annotated_frame)
                        
                        num_detections = len(results[0].boxes)
                        detection_stats.append(num_detections)
                        
                        frame_count += 1
                        if frame_count % 10 == 0:
                            progress = frame_count / total_frames
                            progress_bar.progress(progress)
                            
                            elapsed = time.time() - start_time
                            fps_current = frame_count / elapsed if elapsed > 0 else 0
                            eta = (total_frames - frame_count) / fps_current if fps_current > 0 else 0
                            
                            status_text.text(
                                f"‚è≥ Frame {frame_count}/{total_frames} ({progress:.1%}) | "
                                f"Vitesse: {fps_current:.1f} FPS | "
                                f"ETA: {eta:.0f}s"
                            )
                            
                            frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
                            frame_placeholder.image(frame_rgb, channels="RGB", use_container_width=True)
                    
                    cap.release()
                    out.release()
                    
                    progress_bar.progress(1.0)
                    processing_time = time.time() - start_time
                    status_text.text(f"‚úÖ Traitement termin√© en {processing_time:.1f}s!")
                    
                    st.success("üéâ D√©tection termin√©e!")
                    
                    with open(output_path, 'rb') as video_file:
                        video_bytes = video_file.read()
                    
                    st.download_button(
                        label="üì• T√©l√©charger la vid√©o trait√©e",
                        data=video_bytes,
                        file_name="video_detectee.mp4",
                        mime="video/mp4",
                        use_container_width=True,
                        type="primary"
                    )
                    
                    st.video(video_bytes)
                    
                    if detection_stats:
                        avg_detections = np.mean(detection_stats)
                        max_detections = np.max(detection_stats)
                        total_detections = sum(detection_stats)
                        
                        col_stat1, col_stat2, col_stat3 = st.columns(3)
                        with col_stat1:
                            st.markdown(f"""
                            <div class="success-box">
                                <h3>{total_detections}</h3>
                                <p>D√©tections totales</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        with col_stat2:
                            st.markdown(f"""
                            <div class="success-box">
                                <h3>{avg_detections:.1f}</h3>
                                <p>Moyenne/frame</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        with col_stat3:
                            st.markdown(f"""
                            <div class="success-box">
                                <h3>{max_detections}</h3>
                                <p>Maximum/frame</p>
                            </div>
                            """, unsafe_allow_html=True)
                    
                    try:
                        cap.release()
                        time.sleep(0.5)
                        if os.path.exists(video_path):
                            os.unlink(video_path)
                        if os.path.exists(output_path):
                            os.unlink(output_path)
                    except:
                        pass
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur: {str(e)}")
                    if 'cap' in locals():
                        cap.release()
                    try:
                        if 'video_path' in locals() and os.path.exists(video_path):
                            os.unlink(video_path)
                    except:
                        pass
    else:
        st.info("üëÜ Uploadez une vid√©o pour commencer")

# ========== TAB 4: √Ä PROPOS ==========
with tab4:
    st.header("‚ÑπÔ∏è √Ä Propos de l'Application")
    
    st.markdown("""
    ### üéØ Objectif
    Cette application utilise l'intelligence artificielle (YOLOv8) pour d√©tecter automatiquement 
    si les poubelles sont **pleines** ou **vides**.
    
    ### üöÄ Fonctionnalit√©s
    - ‚úÖ **D√©tection en temps r√©el via webcam** (NOUVEAU!)
    - ‚úÖ D√©tection instantan√©e sur images
    - ‚úÖ Traitement de vid√©os compl√®tes
    - ‚úÖ T√©l√©chargement des r√©sultats annot√©s
    - ‚úÖ T√©l√©chargement du mod√®le pour utilisation hors ligne
    - ‚úÖ Param√®tres ajustables en temps r√©el
    
    ### üõ†Ô∏è Technologies Utilis√©es
    - **YOLOv8** (Ultralytics) - D√©tection d'objets
    - **Streamlit** - Interface web
    - **Streamlit-WebRTC** - Streaming vid√©o en temps r√©el
    - **OpenCV** - Traitement vid√©o
    - **Python** - Langage de programmation
    """)
    
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; margin-top: 30px; color: #666;'>
        <p><strong>üóëÔ∏è D√©tecteur de Poubelles YOLOv8</strong></p>
        <p>D√©velopp√© avec ‚ù§Ô∏è using Streamlit & Ultralytics YOLO</p>
        <p><small>Version 2.0 avec WebRTC - 2024</small></p>
    </div>
    """, unsafe_allow_html=True)
